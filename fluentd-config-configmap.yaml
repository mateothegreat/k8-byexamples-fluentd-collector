apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-configmap
  namespace: $NS
data:
  fluent.conf: |-
    # <match **>
    #     @type elasticsearch
    #     host ${ELASTICSEARCH_HOST}
    #     port ${ELASTICSEARCH_PORT}
    #     log_level ${FLUENT_LOG_LEVEL}
    #     index_name fluentd
    #     type_name fluentd
    #     reload_connections true
    # </match>
    <match fluent.**>
        type null
    </match>
    # Example:
    # {"log":"[info:2016-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2016-02-17T00:04:05.931087621Z"}
    <source>
        type tail
        path /var/log/containers/*.log
        pos_file /var/lib/fluentd/es-containers.log.pos
        time_format %Y-%m-%dT%H:%M:%S.%NZ
        tag kubernetes.*
        format json
        read_from_head true
    </source>
    <filter kubernetes.**>
        type kubernetes_metadata
    </filter>
    <filter kubernetes.**>
        @type grep
        exclude1 kubernetes.container_name fluentd-logging
    </filter>
    <match kubernetes.**>
        @type elasticsearch_dynamic
        host ${ELASTICSEARCH_HOST}
        port ${ELASTICSEARCH_PORT}
        log_level ${FLUENT_LOG_LEVEL}
        include_tag_key true
        logstash_format true
        logstash_prefix kubernetes-${record['kubernetes']['pod_name']}
        # Set the chunk limit the same as for fluentd-gcp.
        buffer_chunk_limit 2M
        # Cap buffer memory usage to 2MiB/chunk * 32 chunks = 64 MiB
        buffer_queue_limit 32
        flush_interval 5s
        # Never wait longer than 5 minutes between retries.
        max_retry_wait 30
        retry_wait 10s
        # Disable the limit on the number of retries (retry forever).
        disable_retry_limit
        # Use multiple threads for processing.
        num_threads 1
    </match>
